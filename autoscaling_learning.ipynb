{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f53ec889-28ea-4980-9861-c6ef21629341",
   "metadata": {},
   "source": [
    "# AutoScale test case for learning purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "7fdc523e-b436-4790-a4bb-c76e4093564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import fcluster, linkage\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea9f524-2a71-4122-af87-28d088800886",
   "metadata": {},
   "source": [
    "## Create response matrix consisting of **independent** responses\n",
    "\n",
    "Drawing random observations and enough samples such that each primary component explains approximately 25% of the variance.\n",
    "Notice that we need quite a few before this is the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "b8c72bdd-4b25-48b9-a9d1-3d36a664ab8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_observations = 4\n",
    "n_realizations = 100\n",
    "# NB! Note the transposing of Y before SVD.\n",
    "Y = rng.normal(size=(n_observations, n_realizations)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14955137-3281-4dae-ad11-98e0df06173f",
   "metadata": {},
   "source": [
    "## Response Scaling\n",
    "\n",
    "Scaling is done as `scaled_responses = responses / obs_errors.reshape(-1, 1)` in the code, but we don't need it here since all observations are drawn from a standard normal distribution.\n",
    "However, it is worth investigating why we don't do standard scaling, i.e., `responses: (responses - mean(responses)) / sd(responses)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559fc94d-4832-4632-8854-19b11005c140",
   "metadata": {},
   "source": [
    "## Find the number of principal components that explain **less** than 95% of the variance\n",
    "\n",
    "Since we here have 4 independent responses, should we also get 4 as the number of components?\n",
    "The current implementation will give 3 and remember that the first 3 components explain only 75% of the variance.\n",
    "Note also that the number of principal components is later used as the number of clusters,\n",
    "which means that we will have to place two of the independent responses into one cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "eeb2dc91-c8c4-42ed-ab6a-526bcdd853ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance_ratio:  [0.29133229 0.56201325 0.80096563 1.        ]\n",
      "number of principal components:  3\n"
     ]
    }
   ],
   "source": [
    "_, s, _ = np.linalg.svd(Y - Y.mean(axis=0), full_matrices=False)\n",
    "variance_ratio = np.cumsum(s**2) / np.sum(s**2)\n",
    "print(\"variance_ratio: \", variance_ratio)\n",
    "threshold = 0.95\n",
    "nr_components = max(len([1 for i in variance_ratio[:-1] if i < threshold]), 1)\n",
    "print(\"number of principal components: \", nr_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c1bfb0-c5a6-4076-ae64-5c7fc64c8b79",
   "metadata": {},
   "source": [
    "# Find clusters\n",
    "\n",
    "Since we are using a correlation as measure of distance, in this case spearman, we will be effected by spurious correlations.\n",
    "From the documentation of `linkage`:\n",
    "\n",
    "`The input y may be either a 1-D condensed distance matrix or a 2-D array of observation vectors.`\n",
    "\n",
    "We are passing in a correlation matrix which is not supported.\n",
    "\n",
    "https://github.com/scipy/scipy/blob/e29dcb65a2040f04819b426a04b60d44a8f69c04/scipy/cluster/hierarchy.py#L1024\n",
    "\n",
    "This needs to be investigated further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "3d5505f1-7443-4e2c-b9b1-e76da2938d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affected by spurious correlations\n",
      "[[ 1.         -0.12441644 -0.00621662 -0.04763276]\n",
      " [-0.12441644  1.          0.00344434  0.06481848]\n",
      " [-0.00621662  0.00344434  1.          0.05968197]\n",
      " [-0.04763276  0.06481848  0.05968197  1.        ]]\n",
      "---------------------\n",
      "Note that there are 3 clusters and not 4: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 1, 2, 1], dtype=int32)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Affected by spurious correlations\")\n",
    "correlation = spearmanr(Y).statistic\n",
    "print(correlation)\n",
    "print(\"---------------------\")\n",
    "\n",
    "# Do we want this instead maybe: linkage_matrix = linkage(Y.T, \"average\", \"correlation\")\n",
    "linkage_matrix = linkage(correlation, \"average\", \"euclidean\")\n",
    "# linkage_matrix = linkage(pdist(Y.T, metric=\"euclidean\"), \"average\")\n",
    "print(\"Note that there are 3 clusters and not 4: \")\n",
    "fcluster(linkage_matrix, nr_components, criterion=\"maxclust\", depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1c0c3e-5484-4bb2-be4d-24fb6000ee6b",
   "metadata": {},
   "source": [
    "## From each cluster, calculate scaling factor to scale observation errors with\n",
    "\n",
    "scaling_factor = sqrt(nr_observations / nr_components) (in each cluster).\n",
    "\n",
    "Not a well known method as far as I know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12acde43-3afb-4049-854f-e58bfc793ee4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
